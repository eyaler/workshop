{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nn_8_viz.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/workshop/blob/master/nn_8_viz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsBFEmpK4tIe"
      },
      "source": [
        "# Computer shows why:\n",
        "\n",
        "## Visualizing machine learning and decision\n",
        "\n",
        "### Dr. Eyal Gruss\n",
        "\n",
        "based on: https://github.com/raghakot/keras-vis/blob/master/examples/vggnet/attention.ipynb\n",
        "\n",
        "slides: https://j.mp/vis-dl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh1dwvmrnFYn"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "# install keras-vis master version\n",
        "!pip install -U git+https://github.com/raghakot/keras-vis.git",
        "\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JWkgsTdnMLd"
      },
      "source": [
        "# download and display some images\n",
        "from vis.utils import utils\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (18, 24)\n",
        "\n",
        "urls = ['https://i.imgur.com/raG3QsN.jpg', 'https://i.imgur.com/DGnn1nt.jpg', 'https://i.imgur.com/tQMznEK.png']\n",
        "\n",
        "imgs = [utils.load_img(url, target_size=(224, 224))[..., :3] for url in urls]\n",
        "\n",
        "f, ax = plt.subplots(1, len(imgs))\n",
        "for i in range(len(imgs)):\n",
        "  ax[i].imshow(imgs[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6SDI1E94tIp"
      },
      "source": [
        "# download imagenet recognition model and predict on images\n",
        "\n",
        "from keras.applications.vgg16 import VGG16 as MODEL, preprocess_input, decode_predictions\n",
        "#from keras.applications.resnet50 import ResNet50 as MODEL, preprocess_input, decode_predictions\n",
        "import json\n",
        "import numpy as np\n",
        "plt.rcParams['axes.labelsize'] = 15\n",
        "\n",
        "top = 5\n",
        "min_prob = 0.01\n",
        "\n",
        "!wget -N https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json\n",
        "with open('imagenet_class_index.json') as f:\n",
        "    CLASS_INDEX = json.load(f)\n",
        "label2index = {CLASS_INDEX[i][1]:int(i) for i in CLASS_INDEX}\n",
        "\n",
        "model = MODEL(weights='imagenet')\n",
        "preproc_imgs = [preprocess_input(img) for img in imgs]\n",
        "probs = [model.predict(np.expand_dims(img, axis=0)) for img in preproc_imgs]\n",
        "preds = [decode_predictions(prob, top=top)[0] for prob in probs]\n",
        "all_preds = [{x[1]:x[2] for x in decode_predictions(prob,top=1000)[0]} for prob in probs]\n",
        "\n",
        "# change final activation from softmax to linear for viz\n",
        "from keras import activations\n",
        "layer_index = -1\n",
        "model.layers[layer_index].activation = activations.linear\n",
        "model_linear = utils.apply_modifications(model)\n",
        "\n",
        "f, ax = plt.subplots(1, len(imgs))\n",
        "for i in range(len(imgs)):\n",
        "  ax[i].imshow(imgs[i])\n",
        "  ax[i].set_xlabel('\\n'.join('\\n%s (%d): %d%%'%(pred[1], label2index[pred[1]], pred[2]*100) for pred in preds[i] if pred[2]>min_prob))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlOObi7gHU0v"
      },
      "source": [
        "from vis.visualization import visualize_saliency, visualize_cam\n",
        "import tensorflow as tf\n",
        "import matplotlib.cm as cm\n",
        "import cv2\n",
        "from IPython.display import Javascript\n",
        "\n",
        "def viz(filter_indices, method='sal', sal_backprop_modifier='guided', cam_backprop_modifier=None, sal_grad_modifier='absolute', cam_grad_modifier=None, layer_index=-1, penultimate_layer_idx=None, quantile=0.99, alpha=0.7, local_alpha=True, linear=True):\n",
        "  display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "  if linear:\n",
        "    model1 = model_linear\n",
        "  else:\n",
        "    model1 = model\n",
        "\n",
        "  f, ax = plt.subplots(3 if method=='cam' else 5, len(imgs))\n",
        "  if method=='cam':\n",
        "    f.set_figheight(12)\n",
        "  for i in range(len(imgs)):\n",
        "    grads = 1\n",
        "    cam = 1\n",
        "    with tf.compat.v1.get_default_graph().gradient_override_map({'LeakyRelu': 'guided'}):\n",
        "      if method in ('sal','sal*cam'):\n",
        "        grads = visualize_saliency(model1, layer_index, filter_indices, preproc_imgs[i], backprop_modifier=sal_backprop_modifier, grad_modifier=sal_grad_modifier)\n",
        "      if method in ('cam','sal*cam'):\n",
        "        cam = visualize_cam(model1, layer_index, filter_indices, preproc_imgs[i], backprop_modifier=cam_backprop_modifier, grad_modifier=cam_grad_modifier, penultimate_layer_idx=None)\n",
        "\n",
        "    ax[0,i].imshow(grads*cam, cmap='jet')\n",
        "    if method!='cam':\n",
        "      if quantile:\n",
        "        grads = np.clip(grads,0,np.quantile(grads, quantile))\n",
        "      ax[1,i].imshow(grads*cam, cmap='jet')\n",
        "\n",
        "      grads = cv2.GaussianBlur(grads, (9,9), 0)\n",
        "      ax[2,i].imshow(grads*cam, cmap='jet')\n",
        "\n",
        "    grads *= cam\n",
        "    if grads.max()>grads.min():\n",
        "      grads = (grads-grads.min())/(grads.max()-grads.min())\n",
        "\n",
        "    heatmap = cm.jet(grads)[...,:3]\n",
        "    gray = imgs[i].mean(axis=-1, keepdims=True)/255\n",
        "    alpha_filter = alpha\n",
        "    if local_alpha:\n",
        "      alpha_filter = alpha*alpha\n",
        "    ax_num = 1 if method=='cam' else 3\n",
        "    ax[ax_num ,i].imshow(alpha_filter*heatmap+(1-alpha_filter)*gray)\n",
        "    if local_alpha:\n",
        "      alpha_filter = alpha*np.expand_dims(grads, axis=-1)\n",
        "      ax_num+=1\n",
        "      ax[ax_num ,i].imshow(alpha_filter*heatmap+(1-alpha_filter)*gray)\n",
        "    if isinstance(filter_indices,int):\n",
        "      ax[ax_num, i].set_xlabel('\\nprob=%.6f'%probs[i][0][filter_indices])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUu6ZqDZKyAG"
      },
      "source": [
        "# simple gradients - not so good\n",
        "viz(filter_indices=label2index['Border_collie'], sal_backprop_modifier=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVRN7IV3JfvG"
      },
      "source": [
        "#Guided Backprop (https://arxiv.org/abs/1412.6806)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkFTqCQ7SWZ-"
      },
      "source": [
        "viz(filter_indices=label2index['Border_collie'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vFDmLELJ6CN"
      },
      "source": [
        "#Note backprop is not descriminative between different output labels:\n",
        "viz(filter_indices=label2index['space_shuttle'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7qWjJ0hrobN"
      },
      "source": [
        "#Grad-CAM (https://arxiv.org/abs/1610.02391)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29pkIWm0Mbfz"
      },
      "source": [
        "viz(filter_indices=label2index['Border_collie'], method='cam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln9UlN4eX4GM"
      },
      "source": [
        "viz(filter_indices=label2index['ram'], method='cam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MEvgLHJc-HQ"
      },
      "source": [
        "#we can see that actually Irish_wolfhound was found for the wrong reasons... but maybe it's acceptible (see image below)\n",
        "viz(filter_indices=label2index['Irish_wolfhound'], method='cam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKx8OmF3zqn3"
      },
      "source": [
        "#da real Irish wolfhound!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fq1S_E6aJzr",
        "cellView": "form"
      },
      "source": [
        "#@title ![da real Irish wolfhound](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Irish_wolfhound_giaccomo.JPG/1024px-Irish_wolfhound_giaccomo.JPG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBnZKlKwaVWe"
      },
      "source": [
        "#Disclaimer: Garbage in garbage out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCVb6FzXtJo6"
      },
      "source": [
        "#note that keras-vis always normalizes (stretches) the grad-cam weights as well as the gradients, so we may always get something (https://github.com/raghakot/keras-vis/issues/178)\n",
        "viz(filter_indices=label2index['space_shuttle'], method='cam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrb7CYnv0vNy"
      },
      "source": [
        "viz(filter_indices=label2index['dishwasher'], method='cam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYofRw6qaoP4"
      },
      "source": [
        "#Nagetive Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBX4oq4UzmKP"
      },
      "source": [
        "#negate - highlight areas that decrease the class output\n",
        "viz(filter_indices=label2index['Border_collie'], method='cam', cam_grad_modifier='negate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4SIQucpy8Ts"
      },
      "source": [
        "viz(filter_indices=label2index['ram'], method='cam', cam_grad_modifier='negate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzaElDw_coSX"
      },
      "source": [
        "viz(filter_indices=label2index['space_shuttle'], method='cam', cam_grad_modifier='negate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRmZoiPVt2M3"
      },
      "source": [
        "#Guided Grad-CAM = Guided Backprop * Grad-CAM (Grad-CAM paper)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9aCws_TuRsE"
      },
      "source": [
        "#note this is different from keras-vis grad-cam with modifier=\"guided\" (https://github.com/raghakot/keras-vis/issues/201)\n",
        "viz(filter_indices=label2index['Border_collie'], method='sal*cam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r-2kzVCS_ek"
      },
      "source": [
        "viz(filter_indices=label2index['ram'], method='sal*cam')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
